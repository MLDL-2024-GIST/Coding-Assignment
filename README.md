# Coding-Assignment
This assignment focuses on understanding and applying the concepts of soft and hard margins, kernel tricks, and optimization methods in Support Vector Machines (SVM). By solving the given problems and compiling a report, you will demonstrate your grasp of these important machine learning techniques.  

## Problem 1
The objective is to employ Support Vector Machines (SVM) to find and visualize a decision boundary that perfectly classifies parts of the Iris dataset. This problem is not only about applying SVM but also understanding how its parameters affect the model's performance, especially under scenarios requiring perfect separation.

### (1) Data Preparation and Visualization  
Visualize the selected data in a scatter plot to understand the initial distribution. Highlight different classes using distinct colors and markers. This visualization will help you assess the feasibility of perfect separation with a linear boundary.   

### (2) Visualizing the decision boundary  
Select an SVM from the visualized graph and use it to draw a decision boundary that perfectly separates the two datasets. The report should include a reasoned explanation of how the decision boundary was drawn based on the SVM.   

### (3) Implementing Hard Margin SVM  
Adjust the SVM settings to enforce a hard margin (e.g., set the C parameter to a very high value). This configuration assumes that the data is linearly separable and aims to classify all training samples correctly without any misclassifications.  
Re-visualize the decision boundary. This visualization should now reflect a stricter separation where the margin is minimized to perfectly classify all training points.

## Problem 2

## Problem 3

## Extra
You can earn extra credit (3 points) for solving this question. 

(1)   
(2)
